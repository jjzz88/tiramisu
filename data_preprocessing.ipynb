{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb1b89b-c025-4aa7-8471-e4657243a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be2a2c-2ced-43a5-a092-ed2a14798e1f",
   "metadata": {},
   "source": [
    "## Count the total number of files\n",
    "\n",
    "Given the path to a folder which may contain subfolders, count the total number of files in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d35330-9416-4052-96b1-27f44592ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_files(path):\n",
    "    files = os.listdir(path)\n",
    "    num_of_files = 0\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(path, file)\n",
    "        if os.path.isdir(path_to_file):\n",
    "            num_of_files += get_number_of_files(path_to_file)\n",
    "        else:\n",
    "            num_of_files += 1\n",
    "    return num_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a160366-fd55-47bc-9cd0-f4256df410d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596457\n"
     ]
    }
   ],
   "source": [
    "print(get_number_of_files(\"CN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f115be-19f7-4f2a-97c9-e487cb761116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129\n"
     ]
    }
   ],
   "source": [
    "print(get_number_of_files(\"CN/A001\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0d366-a544-47c6-8f99-b07c331a043c",
   "metadata": {},
   "source": [
    "## Get the name of all files\n",
    "\n",
    "Given the path to a folder which may contain subfolders, get the name of all files in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ccea03-4922-40e6-a486-d71495e0ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(path):\n",
    "    filenames = []\n",
    "    get_filename_help(path, filenames)\n",
    "    return filenames\n",
    "\n",
    "def get_filename_help(path, filenames):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(path, file)\n",
    "        if os.path.isdir(path_to_file):\n",
    "            get_filename_help(path_to_file, filenames)\n",
    "        else:\n",
    "            filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c04d43-b661-46af-a7e0-071b96b2f60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8129"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_A001 = get_filename(\"CN/A001\")\n",
    "num_of_files_A001 = len(filenames_A001)\n",
    "num_of_files_A001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc3b49-63e2-4e1a-8ef7-5edcde99aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_A001[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a064484-d9d9-487a-bda5-b717887e979b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596457"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_CN = get_filename(\"CN\")\n",
    "num_of_files_CN = len(filenames_CN)\n",
    "num_of_files_CN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5aa74-34d1-43e5-a766-3c4c8f00c03f",
   "metadata": {},
   "source": [
    "## Get unique IDs (i.e. different products)\n",
    "\n",
    "Assume the filename starts with a unique ID (which could be SKU, EAN, etc) followed by underscore. Given the path of a folder which may contain subfolders, get unique IDs (i.e., different products) in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64cfd0fe-a954-4364-8339-8ff22d4c4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_ids(path):\n",
    "    uids = set()\n",
    "    get_unique_ids_help(path, uids)\n",
    "    return uids\n",
    "\n",
    "def get_unique_ids_help(path, uids):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(path, file)\n",
    "        if os.path.isdir(path_to_file):\n",
    "            get_unique_ids_help(path_to_file, uids)\n",
    "        else:\n",
    "            uids.add(file.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46dbdfba-3cfd-48d9-a46c-0510093697a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids_CN = get_unique_ids(\"CN\")\n",
    "number_of_products_CN = len(uids_CN)\n",
    "number_of_products_CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938c67db-8cb3-46f7-971e-39193ec819ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids_A001 = get_unique_ids(\"CN/A001\")\n",
    "number_of_products_A001 = len(uids_A001)\n",
    "number_of_products_A001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be4713-86c6-4a49-b4f7-b1967659acf8",
   "metadata": {},
   "source": [
    "## Get the mapping from unique ID to product description\n",
    "\n",
    "Assume the filename starts with a unique ID (which could be SKU, EAN, etc) followed by underscore and product description. Given the path of a folder which may contain subfolders, get the mapping from unique IDs to product description. The reason is that the unique ID here may be arbitrary, neither SKU nor EAN. Also assume that products with the same EAN have the same description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bff60a6-9ceb-4bb5-bb43-0b8a081c3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_from_uid_to_description(path):\n",
    "    uid_to_description = {}\n",
    "    get_mapping_from_uid_to_description_help(path, uid_to_description)\n",
    "    return uid_to_description\n",
    "\n",
    "def get_mapping_from_uid_to_description_help(path, uid_to_description):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(path, file)\n",
    "        if os.path.isdir(path_to_file):\n",
    "            get_mapping_from_uid_to_description_help(path_to_file, uid_to_description)\n",
    "        else:\n",
    "            s = file.split(\"_\")\n",
    "            if s[0] in uid_to_description:\n",
    "                continue\n",
    "            uid_to_description[s[0]] = s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c080fab9-8822-48b0-9100-da45e90da381",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_description_CN = get_mapping_from_uid_to_description(\"CN\")\n",
    "assert len(uid_to_description_CN.keys()) == number_of_products_CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9354f5e9-dd14-47e7-ba2d-a61982142d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_description_A001 = get_mapping_from_uid_to_description(\"CN/A001\")\n",
    "assert len(uid_to_description_A001.keys()) == number_of_products_A001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed20e8f-9502-4502-992b-1d391670407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in list(uid_to_description_A001.items())[:5]:\n",
    "    print(k + \": \" + v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56392690-9feb-4c5a-a29a-10ff015791f6",
   "metadata": {},
   "source": [
    "## Get mapping from unique ID to file location\n",
    "\n",
    "Assume the filename starts with a unique ID (which could be SKU, EAN, etc) followed by underscore. Given the path of a folder which may contain subfolders, get the mapping from unique ID to a list of locations of the files containing the same product, so that we can split the files between training and testing for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5f4412-0665-423e-a01b-70b7d793bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_from_uid_to_file_location(path):\n",
    "    uid_to_file_locations = collections.defaultdict(list)\n",
    "    get_mapping_from_uid_to_file_location_help(path, uid_to_file_locations)\n",
    "    return uid_to_file_locations\n",
    "\n",
    "def get_mapping_from_uid_to_file_location_help(path, uid_to_file_locations):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(path, file)\n",
    "        if os.path.isdir(path_to_file):\n",
    "            get_mapping_from_uid_to_file_location_help(path_to_file, uid_to_file_locations)\n",
    "        else:\n",
    "            s = file.split(\"_\")\n",
    "            uid_to_file_locations[s[0]].append(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f5c99d2-1416-4893-82c8-046bd918fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_file_locations_A001 = get_mapping_from_uid_to_file_location(\"CN/A001\")\n",
    "assert len(uid_to_file_locations_A001.keys()) == number_of_products_A001\n",
    "assert sum([len(x) for x in uid_to_file_locations_A001.values()]) == num_of_files_A001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d022196-f85b-402a-9ca0-d0d5ce891805",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in list(uid_to_file_locations_A001.items())[:2]:\n",
    "    print(k + \": \")\n",
    "    for x in v:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792e6fdb-2f44-4493-96e1-43cffef0e2c7",
   "metadata": {},
   "source": [
    "## Issue of the data\n",
    "\n",
    "#### Same EAN but different description\n",
    "\n",
    "The following two items have the same EAN but are in two subfolders and have different product description.\n",
    "\n",
    "- CN/A001/6959764600817_依能苏打水饮料/6959764600817_依能苏打水饮料_A_A001_15545.jpg\n",
    "- CN/A001/6959764600817_依能加锌苏打水500毫升/6959764600817_依能加锌苏打水500毫升_A_A001_107505006.jpg\n",
    "\n",
    "之前提到的油漆，不同颜色的油漆是否具有相同的EAN？\n",
    "\n",
    "Should we treat products with the same EAN but different descriptions differently? They are currently treated as the same.\n",
    "\n",
    "#### Fake EAN\n",
    "\n",
    "Some photos are annotated with fake rather than real EAN.\n",
    "\n",
    "#### Undefined description\n",
    "\n",
    "Some photos have undefined description. They are currently treated normally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37aac1-41cb-470b-9a12-8a8e3efc055f",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "Given the path of a folder which may contain subfolders, split files of each product into two parts, one for training and the other for testing, with a specified ratio. Assume that products with the same EAN have the same description. That is, products are only differentiated by EAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5a56e08b-97db-4d3a-b6b8-562c5f7ec53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_ean(path, train_ratio=0.7, seed=43):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    ratio: the proportion of training data\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    uid_to_file_location = get_mapping_from_uid_to_file_location(path)\n",
    "    uid_to_description = get_mapping_from_uid_to_description(path)\n",
    "    train_uid, train_description, train_file_location = [], [], []\n",
    "    test_uid, test_description, test_file_location = [], [], []\n",
    "    for uid in uid_to_file_location.keys():\n",
    "        n = len(uid_to_file_location[uid])\n",
    "        k = int(n * train_ratio)\n",
    "        index = np.random.choice(n, k, replace=False)\n",
    "        train_uid.extend([uid] * k)\n",
    "        train_description.extend([uid_to_description[uid]] * k)\n",
    "        train_file_location.extend([uid_to_file_location[uid][_] for _ in index])\n",
    "        test_uid.extend([uid] * (n - k))\n",
    "        test_description.extend([uid_to_description[uid]] * (n - k))\n",
    "        test_file_location.extend([uid_to_file_location[uid][_] for _ in set(range(n)) - set(index)])\n",
    "    return train_uid, train_description, train_file_location, test_uid, test_description, test_file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b930a3fb-a841-456b-b7e0-b558166bbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_test_split(path, train_uid, train_description, train_file_location, test_uid, test_description, test_file_location):\n",
    "    num_of_files = get_number_of_files(path)\n",
    "    assert len(train_uid) + len(test_uid) == num_of_files\n",
    "    assert len(train_description) + len(test_description) == num_of_files\n",
    "    assert len(train_file_location) + len(test_file_location) == num_of_files\n",
    "    assert len(train_uid) == len(train_description) == len(train_file_location)\n",
    "    assert len(test_uid) == len(test_description) == len(test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a4f2ee06-6ff5-4411-98d2-18eaba8d721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uid, train_description, train_file_location, test_uid, test_description, test_file_location = train_test_split_ean(\"CN/A001\")\n",
    "test_train_test_split(\"CN/A001\", train_uid, train_description, train_file_location, test_uid, test_description, test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ae281869-8f54-462d-9a0e-eb32228b624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5627"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "61c1098c-2bc2-41c8-abf8-43822d1d222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2502"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9d246d7b-3fbf-4520-8930-2c4e781073d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242df3d-d39a-4eb3-9c3b-d321a1e215a5",
   "metadata": {},
   "source": [
    "## Get mapping from uid + description to file location\n",
    "\n",
    "When products are differentiated by both EAN and description, we map uid and description to file location. Assume uid and description are the first two parts in filename separated by underscore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3ef060e4-baa6-4a80-b467-cfa936ae47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_from_uid_description_to_location(path):\n",
    "    uid_description_to_location = collections.defaultdict(list)\n",
    "    get_mapping_from_uid_description_to_location_help(path, uid_description_to_location)\n",
    "    return uid_description_to_location\n",
    "\n",
    "def get_mapping_from_uid_description_to_location_help(path, uid_description_to_location):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(path, file)\n",
    "        if os.path.isdir(path_to_file):\n",
    "            get_mapping_from_uid_description_to_location_help(path_to_file, uid_description_to_location)\n",
    "        else:\n",
    "            s = file.split(\"_\")\n",
    "            uid_description_to_location[s[0] + \"_\" + s[1]].append(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f8af4228-2470-42d8-9e96-6d7b3f164bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_description_to_location_A001 = get_mapping_from_uid_description_to_location(\"CN/A001\")\n",
    "assert len(uid_description_to_location_A001.keys()) >= number_of_products_A001\n",
    "assert sum([len(x) for x in uid_description_to_location_A001.values()]) == num_of_files_A001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c82270-3b2f-4088-bc96-e75c28126cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in list(uid_description_to_location_A001.items())[:2]:\n",
    "    print(k + \": \")\n",
    "    for x in v:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ff87e-ab3f-42d8-bbb5-a4ea000a85b1",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Given the path of a folder which may contain subfolders, split files of each product into two parts, one for training and the other for testing, with a specified ratio. Assume that products with the same EAN may have different descriptions. We differentiate products by both EAN and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7daba79f-e5f6-4fc0-b145-ff529800f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_ean_description(path, train_ratio=0.7, seed=43):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    ratio: the proportion of training data\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    uid_description_to_location = get_mapping_from_uid_description_to_location(path)\n",
    "    train_uid, train_description, train_file_location = [], [], []\n",
    "    test_uid, test_description, test_file_location = [], [], []\n",
    "    for uid_description in uid_description_to_location.keys():\n",
    "        s = uid_description.split(\"_\")\n",
    "        uid = s[0]\n",
    "        description = s[1]\n",
    "        n = len(uid_description_to_location[uid_description])\n",
    "        k = int(n * train_ratio)\n",
    "        index = np.random.choice(n, k, replace=False)\n",
    "        train_uid.extend([uid] * k)\n",
    "        train_description.extend([description] * k)\n",
    "        train_file_location.extend([uid_description_to_location[uid_description][_] for _ in index])\n",
    "        test_uid.extend([uid] * (n - k))\n",
    "        test_description.extend([description] * (n - k))\n",
    "        test_file_location.extend([uid_description_to_location[uid_description][_] for _ in set(range(n)) - set(index)])\n",
    "    return train_uid, train_description, train_file_location, test_uid, test_description, test_file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d94fe9ed-223a-4815-8945-8dbedb599c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uid, train_description, train_file_location, test_uid, test_description, test_file_location = train_test_split_ean_description(\"CN/A001\")\n",
    "test_train_test_split(\"CN/A001\", train_uid, train_description, train_file_location, test_uid, test_description, test_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "91c8c8a6-c14c-4d45-8eca-60f091cd9fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5620"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "30700e9b-1f38-4207-b070-86c5f64220b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "23e611be-200f-4439-ba97-4638337a8eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5620"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cbe9d7ab-6446-4b35-946b-d5233af66daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881809ff-1461-4dc8-9f6a-9bb08d95e42f",
   "metadata": {},
   "source": [
    "## Save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e5aabe7f-dbe4-4522-b358-50cfd8d8eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(dst, uid, description, file_location):\n",
    "    data = {}\n",
    "    data[\"uid\"] = uid\n",
    "    data[\"description\"] = description\n",
    "    data[\"file_location\"] = file_location\n",
    "    with open(dst, 'w', encoding='utf-8') as out_file:\n",
    "        json.dump(data, out_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a11790e3-0254-4f5d-b375-eb717c5e6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(\"A001_train_ean_desc.json\", train_uid, train_description, train_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "02861644-d6e9-4932-b9db-ffc5b5a09422",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(\"A001_test_ean_desc.json\", test_uid, test_description, test_file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd0a08-9413-47bd-ad14-cba9cd148feb",
   "metadata": {},
   "source": [
    "## Load json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "93d43890-39a1-4976-8439-551cffcfb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('A001_train.json', 'r', encoding='utf-8')\n",
    "train_ean_A001 = json.load(file)\n",
    "path = \"A001_test.json\"\n",
    "test_ean_A001 = json.load(open(path, 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "39df2c8a-6648-43d1-a627-322fb44d3bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'description', 'file_location'])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ean_A001.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b26d9b92-0d39-413c-b110-17c01276e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'description', 'file_location'])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ean_A001.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ef549315-41c9-4021-875d-ad32906082d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2502"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ean_A001['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a07bddc7-98f7-4f74-8fc9-dcff15f2188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"A001_train_ean_desc.json\"\n",
    "train_ean_desc_A001 = json.load(open(path, 'r', encoding='utf-8'))\n",
    "path = \"A001_test_ean_desc.json\"\n",
    "test_ean_desc_A001 = json.load(open(path, 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2053cbca-b3af-4f12-9985-e947374da911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['uid', 'description', 'file_location'])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ean_desc_A001.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4dd4493e-2880-4cc3-bcd9-f8c502f309c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5620"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ean_desc_A001['uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e16457-23a2-4ced-b018-cc165c016454",
   "metadata": {},
   "source": [
    "## Clean data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b528c8-c47d-47c7-af9c-772d0c86e145",
   "metadata": {},
   "source": [
    "## 微调数据集\n",
    "\n",
    "- https://zhuanlan.zhihu.com/p/701930953\n",
    "- https://modelscope.cn/datasets/modelscope/coco_2014_caption/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fd8c79f-39e9-42ef-af4e-37cb4ac09c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 09:12:50,831 - modelscope - INFO - PyTorch version 2.2.2 Found.\n",
      "2024-06-14 09:12:50,834 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-06-14 09:12:50,981 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 137712c8ca5ebf0802c740a429d6cceb and a total number of 980 components indexed\n",
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer is not installed, please install it if you want to use related modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:926: FutureWarning: The repository for coco_2014_caption contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /root/.cache/modelscope/hub/datasets/modelscope/coco_2014_caption/master/meta/coco_2014_caption.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████| 14.9M/14.9M [00:12<00:00, 1.17MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████| 4.93M/4.93M [00:04<00:00, 1.16MB/s]\n",
      "Generating train split: 414113 examples [00:13, 31531.41 examples/s]\n",
      "Generating validation split: 40504 examples [00:01, 30367.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uniq_id': '258768', 'image_id': '11195', 'caption': 'A snow skier assessing the mountain before starting to sky', 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480 at 0x791E21F79CF0>}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "ds = MsDataset.load(\"coco_2014_caption\", namespace=\"modelscope\", split=\"train\")\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d30297f-f5f6-45f5-854f-568ffbe6dba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uniq_id': ['258768',\n",
       "  '725439',\n",
       "  '580123',\n",
       "  '283575',\n",
       "  '392682',\n",
       "  '154143',\n",
       "  '142231',\n",
       "  '569327',\n",
       "  '434237',\n",
       "  '480315'],\n",
       " 'image_id': ['11195',\n",
       "  '367065',\n",
       "  '213997',\n",
       "  '370736',\n",
       "  '524048',\n",
       "  '427137',\n",
       "  '579907',\n",
       "  '45468',\n",
       "  '35230',\n",
       "  '284155'],\n",
       " 'caption': ['A snow skier assessing the mountain before starting to sky',\n",
       "  'a guy that is brushing his teeth and a baby too',\n",
       "  'A chair and a fireplace in a room.',\n",
       "  'A red street sign showing Volt street and Mill street.',\n",
       "  'A young man standing next to a pile of pallets.',\n",
       "  'Some sheep walking in the field and having some fun.',\n",
       "  'A living room complete with couches, television, and fireplace.',\n",
       "  'a bath room with a toilet and a sink and a pile of trash',\n",
       "  \"Two pizza's salad's and drinks on a table with plates.\",\n",
       "  'A clean kitchen with white cabinets and a black oven'],\n",
       " 'image': [<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=375x500>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=639x640>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=250x188>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x480>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x425>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x427>,\n",
       "  <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=640x427>]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6ab9b-5781-4879-9760-670e4db83ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
