{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e16b55-17ad-4446-a062-9f5a9afa7b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run sh: `python /workspace/swift/swift/cli/infer.py --ckpt_dir output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050 --dataset CN_A001_train_glm_4v_9b_description_42_100.json --merge_lora true`\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "2024-06-20 02:27:26,548 - modelscope - INFO - PyTorch version 2.2.2 Found.\n",
      "2024-06-20 02:27:26,549 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-06-20 02:27:26,944 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 137712c8ca5ebf0802c740a429d6cceb and a total number of 980 components indexed\n",
      "[INFO:swift] Successfully registered `/workspace/swift/swift/llm/data/dataset_info.json`\n",
      "[INFO:swift] Start time of running main: 2024-06-20 02:27:28.277604\n",
      "[INFO:swift] ckpt_dir: /workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050\n",
      "[INFO:swift] Setting model_info['revision']: master\n",
      "[INFO:swift] Setting self.eval_human: False\n",
      "[INFO:swift] Setting overwrite_generation_config: True\n",
      "[INFO:swift] args: InferArguments(model_type='glm4v-9b-chat', model_id_or_path='/workspace/swift/glm-4v-9b', model_revision='master', sft_type='lora', template_type='glm4v', infer_backend='pt', ckpt_dir='/workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050', load_args_from_ckpt_dir=True, load_dataset_config=False, eval_human=False, seed=42, dtype='bf16', dataset=['CN_A001_train_glm_4v_9b_description_42_100.json'], val_dataset=[], dataset_seed=42, dataset_test_ratio=0.01, show_dataset_sample=10, save_result=True, system=None, tools_prompt='react_en', max_length=None, truncation_strategy='delete', check_dataset_strategy='none', model_name=[None, None], model_author=[None, None], quant_method=None, quantization_bit=0, hqq_axis=0, hqq_dynamic_config_path=None, bnb_4bit_comp_dtype='bf16', bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_quant_storage=None, max_new_tokens=2048, do_sample=True, temperature=0.3, top_k=20, top_p=0.7, repetition_penalty=1.0, num_beams=1, stop_words=None, rope_scaling=None, use_flash_attn=None, ignore_args_error=False, stream=True, merge_lora=True, merge_device_map='cpu', save_safetensors=True, overwrite_generation_config=True, verbose=None, local_repo_path=None, custom_register_path=None, custom_dataset_info=None, device_map_config_path=None, gpu_memory_utilization=0.9, tensor_parallel_size=1, max_model_len=None, disable_custom_all_reduce=True, enforce_eager=False, vllm_enable_lora=False, vllm_max_lora_rank=16, lora_modules=[], self_cognition_sample=0, train_dataset_sample=-1, val_dataset_sample=None, safe_serialization=None, model_cache_dir=None, merge_lora_and_save=None, custom_train_dataset_path=[], custom_val_dataset_path=[], vllm_lora_modules=None)\n",
      "[INFO:swift] Global seed set to 42\n",
      "[INFO:swift] replace_if_exists: False\n",
      "[INFO:swift] merged_lora_path: `/workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050-merged`\n",
      "[INFO:swift] merge_device_map: cpu\n",
      "[INFO:swift] device_count: 0\n",
      "[INFO:swift] Loading the model using model_dir: /workspace/swift/glm-4v-9b\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|████████████████| 15/15 [00:02<00:00,  6.01it/s]\n",
      "[INFO:swift] model.max_model_len: 8192\n",
      "[INFO:swift] generation_config: GenerationConfig {\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151329,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 151329,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.7\n",
      "}\n",
      "\n",
      "[INFO:swift] PeftModelForCausalLM: 13909.1062M Params (0.0000M Trainable [0.0000%]), 0.0000M Buffers.\n",
      "[INFO:swift] system: None\n",
      "[INFO:swift] Merge LoRA...\n",
      "[INFO:swift] Saving merged weights...\n",
      "[INFO:swift] Successfully merged LoRA and saved in /workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050-merged.\n",
      "[INFO:swift] Setting args.sft_type: 'full'\n",
      "[INFO:swift] Setting args.ckpt_dir: /workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050-merged\n",
      "[INFO:swift] device_count: 0\n",
      "[INFO:swift] Loading the model using model_dir: /workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050-merged\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████████████| 6/6 [00:01<00:00,  3.97it/s]\n",
      "[INFO:swift] model.max_model_len: 8192\n",
      "[INFO:swift] model_config: ChatGLMConfig {\n",
      "  \"_name_or_path\": \"/workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050-merged\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"boi_token_id\": 151339,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eoi_token_id\": 151340,\n",
      "  \"eos_token_id\": [\n",
      "    151329,\n",
      "    151336,\n",
      "    151338\n",
      "  ],\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1.5625e-07,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 40,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 151329,\n",
      "  \"padded_vocab_size\": 151552,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"rmsnorm\": true,\n",
      "  \"rope_ratio\": 1,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vision_config\": {\n",
      "    \"dropout_prob\": 0.0,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_size\": 1792,\n",
      "    \"image_size\": 1120,\n",
      "    \"in_channels\": 3,\n",
      "    \"intermediate_size\": 15360,\n",
      "    \"layer_norm_eps\": 1e-06,\n",
      "    \"num_heads\": 16,\n",
      "    \"num_hidden_layers\": 63,\n",
      "    \"num_positions\": 6401,\n",
      "    \"patch_size\": 14,\n",
      "    \"scaling_factor\": 8\n",
      "  },\n",
      "  \"vocab_size\": 151552\n",
      "}\n",
      "\n",
      "[INFO:swift] generation_config: GenerationConfig {\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151329,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 151329,\n",
      "  \"temperature\": 0.3,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.7\n",
      "}\n",
      "\n",
      "[INFO:swift] [transformer.embedding.word_embeddings.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.input_layernorm.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.self_attention.query_key_value.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.self_attention.query_key_value.bias]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.self_attention.dense.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.post_attention_layernorm.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.mlp.dense_h_to_4h.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.0.mlp.dense_4h_to_h.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.input_layernorm.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.self_attention.query_key_value.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.self_attention.query_key_value.bias]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.self_attention.dense.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.post_attention_layernorm.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.mlp.dense_h_to_4h.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.1.mlp.dense_4h_to_h.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.2.input_layernorm.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.2.self_attention.query_key_value.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.2.self_attention.query_key_value.bias]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.2.self_attention.dense.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] [transformer.encoder.layers.2.post_attention_layernorm.weight]: requires_grad=True, dtype=torch.bfloat16, device=cpu\n",
      "[INFO:swift] ...\n",
      "[INFO:swift] ChatGLMForConditionalGeneration(\n",
      "  (transformer): ChatGLMModel(\n",
      "    (embedding): Embedding(\n",
      "      (word_embeddings): Embedding(151552, 4096)\n",
      "    )\n",
      "    (rotary_pos_emb): RotaryEmbedding()\n",
      "    (encoder): GLMTransformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-39): 40 x GLMBlock(\n",
      "          (input_layernorm): RMSNorm()\n",
      "          (self_attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=4608, bias=True)\n",
      "            (core_attention): CoreAttention(\n",
      "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (post_attention_layernorm): RMSNorm()\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
      "            (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layernorm): RMSNorm()\n",
      "    )\n",
      "    (output_layer): Linear(in_features=4096, out_features=151552, bias=False)\n",
      "    (vision): EVA2CLIPModel(\n",
      "      (patch_embedding): PatchEmbedding(\n",
      "        (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "        (position_embedding): Embedding(6401, 1792)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layers): ModuleList(\n",
      "          (0-62): 63 x TransformerLayer(\n",
      "            (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "            (attention): Attention(\n",
      "              (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "              (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "              (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (mlp): MLP(\n",
      "              (activation_fn): GELUActivation()\n",
      "              (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "              (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "            )\n",
      "            (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (linear_proj): GLU(\n",
      "        (linear_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (act1): GELU(approximate='none')\n",
      "        (dense_h_to_4h): Linear(in_features=4096, out_features=13696, bias=False)\n",
      "        (gate_proj): Linear(in_features=4096, out_features=13696, bias=False)\n",
      "        (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "      )\n",
      "      (conv): Conv2d(1792, 4096, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO:swift] ChatGLMForConditionalGeneration: 13906.3209M Params (13906.3209M Trainable [100.0000%]), 0.0000M Buffers.\n",
      "[INFO:swift] system: None\n",
      "[INFO:swift] show_dataset_sample: 10\n",
      "[INFO:swift] val_dataset: Dataset({\n",
      "    features: ['query', 'response', 'images'],\n",
      "    num_rows: 10\n",
      "})\n",
      "[INFO:swift] Setting args.verbose: True\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]康师傅喝开水550ml <|endoftext|>\n",
      "\n",
      "[LABELS]碱天然泉水\n",
      "[IMAGES]['CN/A001/6971551171010_碱天然泉水/6971551171010_碱天然泉水_A_A001_161945.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是“凉白开”。 <|endoftext|>\n",
      "\n",
      "[LABELS]今麦郎凉白开\n",
      "[IMAGES]['CN/A001/6939729902255_今麦郎凉白开/6939729902255_今麦郎凉白开_A_A001_97325006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是怡宝饮用纯净水。 <|endoftext|>\n",
      "\n",
      "[LABELS]6954767475172\n",
      "[IMAGES]['CN/A001/6954767475172_纯悦包装饮用水 4.5L/6954767475172_6954767475172_纯悦包装饮用水 4.5L_A_A001_1842492467431373.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是“屈臣氏饮用水”。 <|endoftext|>\n",
      "\n",
      "[LABELS]屈臣氏饮用水（蒸馏制法）600ml\n",
      "[IMAGES]['CN/A001/6920180219334_屈臣氏饮用水（蒸馏制法）600ml/6920180219334_屈臣氏饮用水（蒸馏制法）600ml_A_A001_52375006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是C'estbon，中文名为赛特邦。 <|endoftext|>\n",
      "\n",
      "[LABELS]怡宝饮用纯净水555毫升\n",
      "[IMAGES]['CN/A001/6901285991219_怡宝饮用纯净水555毫升/6901285991219_怡宝饮用纯净水555毫升_A_A001_18245006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是怡宝饮用纯净水。 <|endoftext|>\n",
      "\n",
      "[LABELS]纯悦饮用水4.5升\n",
      "[IMAGES]['CN/A001/6901939711590_纯悦饮用水4.5升/6901939711590_纯悦饮用水4.5升_A_A001_31135006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是屈臣氏饮用水。 <|endoftext|>\n",
      "\n",
      "[LABELS]屈臣氏饮用水（蒸馏制法）600ml\n",
      "[IMAGES]['CN/A001/6920180219334_屈臣氏饮用水（蒸馏制法）600ml/6920180219334_屈臣氏饮用水（蒸馏制法）600ml_A_A001_52155006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]圣培露(San Pellucro) <|endoftext|>\n",
      "\n",
      "[LABELS]圣培露圣培露充气天然矿泉水\n",
      "[IMAGES]['CN/A001/8002270019975_圣培露圣培露充气天然矿泉水/8002270019975_圣培露圣培露充气天然矿泉水_A_A001_113105006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是“怡宝饮用纯净水”。 <|endoftext|>\n",
      "\n",
      "[LABELS]娃哈哈饮用纯净水596ml\n",
      "[IMAGES]['CN/A001/6902083881405_娃哈哈饮用纯净水596ml/6902083881405_娃哈哈饮用纯净水596ml_A_A001_33435006.jpg']\n",
      "--------------------------------------------------\n",
      "[PROMPT][gMASK] <sop> <|user|> \n",
      " <|begin_of_image|> <|endoftext|> <|end_of_image|> 图中商品的名称是什么 <|assistant|>[OUTPUT]图中商品的名称是“康师傅喝开水”。 <|endoftext|>\n",
      "\n",
      "[LABELS]康师傅喝开水550ml\n",
      "[IMAGES]['CN/A001/6920459939369_康师傅喝开水550ml_6/6920459939369_康师傅喝开水550ml_6_A_A001_58205006.jpg']\n",
      "--------------------------------------------------\n",
      "[INFO:swift] save_result_path: /workspace/swift/output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050-merged/infer_result/20240620-023205.jsonl\n",
      "[INFO:swift] You can set `--show_dataset_sample -1` to perform inference on the entire dataset.\n",
      "[INFO:swift] End time of running main: 2024-06-20 03:02:39.954102\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 swift infer --ckpt_dir 'output/glm4v-9b-chat/v11-20240619-093735/checkpoint-2050' --dataset CN_A001_train_glm_4v_9b_description_42_100.json --merge_lora true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6862a-74e6-43c1-84f5-09ff39ab1dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
